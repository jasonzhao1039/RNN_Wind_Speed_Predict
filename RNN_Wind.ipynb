{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4a05bc4-e489-4e9a-8971-660fc6967ddb",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network for Wind Speed Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8752aba-257d-4664-8e4f-2af5777a947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b1d22f-8eaa-4ecf-8dae-53c92bd1f928",
   "metadata": {},
   "source": [
    "## DATA\n",
    "Your data is saved in a `.mat` file called <code>hot_wire_data</code> in the usual directory (<code>''/resource/asnlib/publicdata</code>). It consists of a mutlidimensional time series of measurements saved as variables. \n",
    "\n",
    "The file contains all measurement parameters but only two are needed: `U` - the measured speed at two locations and `samp_rate` - frequency of measurements which will be essential in creating a time variable. We will be working with the second location (second column of `U`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2211174c-63fb-4027-a50e-48dda2b48679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AtmP', 'KinVisc', 'TempK', 'U', 'Uinfty', 'Utau', 'd1', 'd2', 'd99', 'dH', 'samp_rate', 'x_since_tripping', 'y']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File('D:/GitHub/RNN_Wind_Speed_Predict/resource/asnlib/publicdata/hot_wire_data.mat', 'r') as f:\n",
    "    U = list(f['U'])\n",
    "    freq = list(f['samp_rate'])\n",
    "    \n",
    "    #显示文件中所有变量的名称，可以了解数据的结构\n",
    "    print(list(f.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f93217-347a-4542-ae1c-6d66682ac7c7",
   "metadata": {},
   "source": [
    "Create datasets for training and testing. Use the frequency to create a variable of time elapsed during the measurement, expressed in seconds. Make sure you only use the second column of `U` for your predictions (only the second location). To prevent kernel timeout, we are only going to be working with the first 10 000 time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3123ab80-eb11-436e-9f99-7dcfd94718ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataset(U, freq, split_ratio):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    #Convert U to np array and store in X\n",
    "    X = np.array(U)\n",
    "    #行列转换\n",
    "    X = X.T\n",
    "    #Take second column of U\n",
    "    X = X[:, 1]   \n",
    "    #上面操作将X编程一维的了，这里将一维张量变成二维\n",
    "    X=X.reshape(-1, 1)\n",
    "    #题目要求只用前10000 time step\n",
    "    X = X[:10000]\n",
    "    \n",
    "\n",
    "    #Create time array\n",
    "    time = np.arange(len(X)) / freq\n",
    "    #行列转换\n",
    "    time = time.T\n",
    "    #题目要求只用前10000 time step\n",
    "    time = time[:10000]\n",
    "    \n",
    "    \n",
    "    #计算train和validation set的数量\n",
    "    n_train = int(len(X)* split_ratio)\n",
    "    n_val = int(len(X)* round(1.0-split_ratio, 3))#round因为python这里bug算出来不是整数 \n",
    "    \n",
    "    \n",
    "    # Splitting\n",
    "    x_train, time_train = X[:n_train], time[:n_train]\n",
    "    x_valid, time_valid = X[n_train:n_train+n_val], time[n_train:n_train+n_val]\n",
    "\n",
    "    ###\n",
    "    return time_train, x_train, time_valid, x_valid\n",
    "split_ratio = 0.8\n",
    "time_train, x_train, time_valid, x_valid = prep_dataset(U,freq,split_ratio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dcd5287-26e6-42b7-8d44-654869fd5d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "assert time_train[n] == n/freq[0],\"Make sure you convert your frequency to time elapsed\"\n",
    "assert len(time_train)/len(time_valid) == 4,\"Make sure you split your time elapsed as well as the data itself\"\n",
    "assert len(x_train)/len(x_valid) == 4,\"Make sure 80% of your data is in the training set\"\n",
    "assert len(x_train) + len(x_valid) == 10000, \"Include only the first 10 000 time steps in your datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf89f8f9-8f83-4222-a93a-3f6180030641",
   "metadata": {},
   "source": [
    "### Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e66ddbb-0590-4bee-b1a1-d32d30db2f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    # 创建TensorFlow的数据集\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "    # 将数据集分割成指定长度的窗口，每个窗口长度为 window_size + 1\n",
    "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    # 将窗口展平为张量\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
    "    # 将每个窗口分为输入和标签（最后一个值作为标签，前面的作为输入特征）\n",
    "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "    # 打乱数据集以防止模型过拟合\n",
    "    dataset = dataset.shuffle(buffer_size=max(1, shuffle_buffer))\n",
    "    # 分批次（batch）处理\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "    ###\n",
    "    return dataset\n",
    "\n",
    "# Create training and test sets\n",
    "# Define your window_size, batch_size and shuffle_buffer_size below\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "\n",
    "window_size = 50\n",
    "batch_size = 32\n",
    "shuffle_buffer_size = 100\n",
    "\n",
    "valid_dataset = windowed_dataset(x_valid, \n",
    "                            window_size, \n",
    "                            batch_size, \n",
    "                            shuffle_buffer=shuffle_buffer_size)\n",
    "\n",
    "###\n",
    "train_dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
    "test_dataset = windowed_dataset(x_valid, window_size, batch_size, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fe65a2-8cc4-4c03-98e2-c2d1a4ea74ef",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da4fea76-aca2-453a-8f7d-130c0453a247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jason\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\lambda_layer.py:65: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jason\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │           \u001b[38;5;34m4,352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │           \u001b[38;5;34m8,320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,785</span> (57.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,785\u001b[0m (57.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,785</span> (57.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,785\u001b[0m (57.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_model():\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    #RNN和LSTM层的单元数（隐藏节点数）\n",
    "    n_units=32\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "                    # The Lambda layer adds an extra dimension to the input to \n",
    "                    # match the expected input shape to RNN layers.\n",
    "                    tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis = -1), \n",
    "                                           input_shape = [None]),\n",
    "        \n",
    "                    # These 4 layers are the RNN model. \n",
    "                    #LSTM层\n",
    "                    tf.keras.layers.LSTM(units=n_units, \n",
    "                                         return_sequences = True), # Required for shape compatibility with SimpleRNN\n",
    "        \n",
    "                    # These 4 layers are the RNN model. \n",
    "                    #LSTM层\n",
    "                    tf.keras.layers.LSTM(units=n_units, \n",
    "                                         return_sequences = True), # Required for shape compatibility with SimpleRNN\n",
    "        \n",
    "                \n",
    "        \n",
    "                    # SimpleRNN 层，用于捕获短期依赖性\n",
    "                    tf.keras.layers.SimpleRNN(units=n_units), \n",
    "        \n",
    "                    # Connect the RNN model to the output label (size 1)\n",
    "                    #全连接层\n",
    "                    tf.keras.layers.Dense(units=1),\n",
    "        \n",
    "                    # This last Lambda layer scales the output by 100 to match \n",
    "                    # the target scale, which is often useful in regression problems.  \n",
    "                    tf.keras.layers.Lambda(lambda x: x * 20.0) \n",
    "                    ])\n",
    "    \n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(),#使用Adam优化器\n",
    "                  loss = tf.keras.losses.Huber(),#使用Huber损失\n",
    "                  metrics = ['mae', 'mape'])#评价指标使用平均绝对差（mae）\n",
    "    \n",
    "    ###\n",
    "    return model\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b278dbd9-a8da-461b-a10b-7db6c4286e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in train_dataset:\n",
    "    assert example[0].numpy().shape[1] == window_size\n",
    "    assert example[0].numpy().shape[0] <= batch_size\n",
    "assert type(window_size)==int and type(batch_size) == int and type(shuffle_buffer_size)==int, \"Define the 3 integer variables for windowing\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbea6e3-0a96-4f9b-a523-948e3d3461cb",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17977aca-393b-41ec-a983-31cc4af794f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "    249/Unknown \u001b[1m26s\u001b[0m 66ms/step - loss: 0.4708 - mae: 0.7408 - mape: 7.6897"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jason\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 78ms/step - loss: 0.4695 - mae: 0.7391 - mape: 7.6724 - val_loss: 0.0112 - val_mae: 0.1112 - val_mape: 1.1847\n",
      "Epoch 2/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 70ms/step - loss: 0.0148 - mae: 0.1341 - mape: 1.3934 - val_loss: 0.0270 - val_mae: 0.2077 - val_mape: 2.3208\n",
      "Epoch 3/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 77ms/step - loss: 0.0128 - mae: 0.1281 - mape: 1.3240 - val_loss: 0.0066 - val_mae: 0.0855 - val_mape: 0.8983\n",
      "Epoch 4/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 83ms/step - loss: 0.0102 - mae: 0.1119 - mape: 1.1599 - val_loss: 0.0035 - val_mae: 0.0603 - val_mape: 0.6382\n",
      "Epoch 5/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 71ms/step - loss: 0.0110 - mae: 0.1126 - mape: 1.1663 - val_loss: 0.0036 - val_mae: 0.0639 - val_mape: 0.6771\n",
      "Epoch 6/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 77ms/step - loss: 0.0058 - mae: 0.0845 - mape: 0.8775 - val_loss: 0.0031 - val_mae: 0.0595 - val_mape: 0.6284\n",
      "Epoch 7/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 78ms/step - loss: 0.0071 - mae: 0.0934 - mape: 0.9667 - val_loss: 0.0028 - val_mae: 0.0558 - val_mape: 0.5881\n",
      "Epoch 8/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 90ms/step - loss: 0.0068 - mae: 0.0901 - mape: 0.9230 - val_loss: 0.0015 - val_mae: 0.0394 - val_mape: 0.4219\n",
      "Epoch 9/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 85ms/step - loss: 0.0065 - mae: 0.0922 - mape: 0.9550 - val_loss: 0.0013 - val_mae: 0.0354 - val_mape: 0.3777\n",
      "Epoch 10/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 73ms/step - loss: 0.0044 - mae: 0.0717 - mape: 0.7364 - val_loss: 0.0029 - val_mae: 0.0673 - val_mape: 0.7395\n",
      "Epoch 11/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 77ms/step - loss: 0.0056 - mae: 0.0835 - mape: 0.8598 - val_loss: 0.0013 - val_mae: 0.0375 - val_mape: 0.3981\n",
      "Epoch 12/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 67ms/step - loss: 0.0050 - mae: 0.0771 - mape: 0.8017 - val_loss: 9.2514e-04 - val_mae: 0.0311 - val_mape: 0.3357\n",
      "Epoch 13/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 65ms/step - loss: 0.0034 - mae: 0.0622 - mape: 0.6412 - val_loss: 0.0033 - val_mae: 0.0702 - val_mape: 0.7448\n",
      "Epoch 14/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - loss: 0.0043 - mae: 0.0749 - mape: 0.7753 - val_loss: 7.7809e-04 - val_mae: 0.0281 - val_mape: 0.3018\n",
      "Epoch 15/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 67ms/step - loss: 0.0036 - mae: 0.0684 - mape: 0.7108 - val_loss: 7.8429e-04 - val_mae: 0.0288 - val_mape: 0.3126\n",
      "Epoch 16/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 72ms/step - loss: 0.0033 - mae: 0.0635 - mape: 0.6490 - val_loss: 0.0011 - val_mae: 0.0396 - val_mape: 0.4346\n",
      "Epoch 17/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - loss: 0.0028 - mae: 0.0569 - mape: 0.5909 - val_loss: 0.0021 - val_mae: 0.0573 - val_mape: 0.6241\n",
      "Epoch 18/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 70ms/step - loss: 0.0047 - mae: 0.0779 - mape: 0.8071 - val_loss: 0.0068 - val_mae: 0.1110 - val_mape: 1.1926\n",
      "Epoch 19/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 83ms/step - loss: 0.0047 - mae: 0.0803 - mape: 0.8400 - val_loss: 0.0023 - val_mae: 0.0590 - val_mape: 0.6302\n",
      "Epoch 20/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 72ms/step - loss: 0.0026 - mae: 0.0589 - mape: 0.6110 - val_loss: 7.5106e-04 - val_mae: 0.0310 - val_mape: 0.3362\n",
      "Epoch 21/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 68ms/step - loss: 0.0034 - mae: 0.0647 - mape: 0.6726 - val_loss: 0.0010 - val_mae: 0.0386 - val_mape: 0.4170\n",
      "Epoch 22/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 68ms/step - loss: 0.0030 - mae: 0.0582 - mape: 0.5900 - val_loss: 0.0020 - val_mae: 0.0580 - val_mape: 0.6378\n",
      "Epoch 23/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 70ms/step - loss: 0.0024 - mae: 0.0552 - mape: 0.5670 - val_loss: 4.3950e-04 - val_mae: 0.0213 - val_mape: 0.2288\n",
      "Epoch 24/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 71ms/step - loss: 0.0030 - mae: 0.0590 - mape: 0.6042 - val_loss: 0.0011 - val_mae: 0.0411 - val_mape: 0.4489\n",
      "Epoch 25/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 70ms/step - loss: 0.0012 - mae: 0.0381 - mape: 0.3976 - val_loss: 5.5960e-04 - val_mae: 0.0266 - val_mape: 0.2877\n",
      "Epoch 26/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 67ms/step - loss: 0.0026 - mae: 0.0526 - mape: 0.5437 - val_loss: 3.8798e-04 - val_mae: 0.0203 - val_mape: 0.2164\n",
      "Epoch 27/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 68ms/step - loss: 0.0023 - mae: 0.0512 - mape: 0.5222 - val_loss: 0.0019 - val_mae: 0.0549 - val_mape: 0.5854\n",
      "Epoch 28/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 70ms/step - loss: 0.0034 - mae: 0.0645 - mape: 0.6552 - val_loss: 0.0027 - val_mae: 0.0692 - val_mape: 0.7570\n",
      "Epoch 29/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 67ms/step - loss: 0.0019 - mae: 0.0507 - mape: 0.5262 - val_loss: 3.8144e-04 - val_mae: 0.0210 - val_mape: 0.2274\n",
      "Epoch 30/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 73ms/step - loss: 0.0022 - mae: 0.0527 - mape: 0.5416 - val_loss: 0.0013 - val_mae: 0.0427 - val_mape: 0.4525\n"
     ]
    }
   ],
   "source": [
    "def train_model(train_dataset):\n",
    "    start_time = time.time()\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    history = model.fit(train_dataset, \n",
    "                        epochs = 30, validation_data=valid_dataset)\n",
    "    \n",
    "    \n",
    "    ###\n",
    "    end_time = time.time()\n",
    "    runtime = end_time-start_time\n",
    "    return runtime, history, model#train using optimal learning rate and no. of epochs\n",
    "runtime, history, model = train_model(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f31223-ed87-4375-b44b-dccbc82a9c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the loss using this cell\n",
    "epochs = range(len(history.history['loss']))\n",
    "\n",
    "\n",
    "plt.plot  ( epochs, history.history['mape'], label = 'mape')\n",
    "# plt.plot  ( epochs, history.history['val_loss'], label = 'Validation')\n",
    "plt.title ('Training and validation loss and mape')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend();\n",
    "#plt.ylim([0,0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67ad8d8-f483-4d9a-993e-ad9875aec83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert runtime <= 1500, \"Your model takes too long to train\"\n",
    "evaluations = model.evaluate(test_dataset)\n",
    "mydict = {a:b for a,b in zip(model.metrics_names, evaluations)}\n",
    "assert mydict['mape']!=None,\"Please, include Mean Absolute Percentage Error (mape) as one of your metrics\" #checks if accuracy included in metrics\n",
    "assert mydict['mape']<0.5, \"Your model needs to have evaluation MAPE of at most 0.5% and actual prediction MAPE of at most 10%. Try expanding your model, changing learning rate or training for more epochs.\" #checks if accuracy greater than 80%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4956a23-b751-49f8-b28f-4b7bfdd7c010",
   "metadata": {},
   "source": [
    "## EVALUATE\n",
    "Use the optimised model to predict and plot the validation data. Stop the loop before reaching the beginning of the last window, otherwise, your code will run out of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a705888-a660-4317-8a7c-e151733028b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = model.predict(test_dataset)\n",
    "# Plot your results alongside ground truth\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time_valid[window_size:],x_valid[window_size:], label='data')\n",
    "plt.plot(time_valid[window_size:],forecast, label='RNN prediction on validation data')\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('label')\n",
    "plt.title('RNN prediction')\n",
    "plt.legend()\n",
    "plt.ylim([9,9.5])\n",
    "plt.xlim([0.145,0.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4aaed252-c1ee-47ab-84c2-02bc33c96b6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras._tf_keras.keras.metrics' has no attribute 'mean_absolute_percentage_error'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAPE= \u001b[39m\u001b[38;5;124m'\u001b[39m,np\u001b[38;5;241m.\u001b[39mmean(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mmean_absolute_percentage_error(x_valid[window_size:], np\u001b[38;5;241m.\u001b[39marray(forecast))\u001b[38;5;241m.\u001b[39mnumpy()))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mmean_absolute_percentage_error(x_valid[window_size:], np\u001b[38;5;241m.\u001b[39marray(forecast))\u001b[38;5;241m.\u001b[39mnumpy())\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour error is too large. Try improving your model or train for longer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras._tf_keras.keras.metrics' has no attribute 'mean_absolute_percentage_error'"
     ]
    }
   ],
   "source": [
    "print('MAPE= ',np.mean(tf.keras.metrics.mean_absolute_percentage_error(x_valid[window_size:], np.array(forecast)).numpy()))\n",
    "assert np.mean(tf.keras.metrics.mean_absolute_percentage_error(x_valid[window_size:], np.array(forecast)).numpy())<=10, \"Your error is too large. Try improving your model or train for longer\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
